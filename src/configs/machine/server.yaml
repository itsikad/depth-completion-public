# @package _global_
trainer: 
  accelerator: 'ddp'
  num_nodes: 1
  gpus: 8
  max_epochs: 50
  num_sanity_val_steps: 2
  check_val_every_n_epoch: 1
  sync_batchnorm: true

dataloader:
  batch_size: 1
  num_workers: 20
  pin_memory: true